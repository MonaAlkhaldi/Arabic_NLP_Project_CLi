# ğŸŒ™ Arabic NLP Classification CLI

<div align="center">

### *From Raw Arabic Text to Production-Ready Models in One Command*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![CLI](https://img.shields.io/badge/CLI-Tool-green.svg)](https://github.com/yourusername/arabic-nlp-cli)
[![Arabic](https://img.shields.io/badge/Language-Arabic-orange.svg)](https://en.wikipedia.org/wiki/Arabic)

</div>


## ğŸ¯ The Problem

You have Arabic text data. You need a classification model. Between you and production are:
- Data exploration notebooks
- Preprocessing scripts with encoding nightmares
- Embedding experiments across multiple files
- Training code scattered everywhere
- Performance tracking in random cells

**Days of work. Dozens of files. One headache.**

## âœ¨ The Solution

```bash
# One command. One pipeline. Done.
python main.py pipeline reviews.csv review_text rating --embed model2vec

```
**5 minutes later:**
- âœ… Exploratory visualizations generated
- âœ… 40,000+ texts preprocessed and normalized
- âœ… Semantic embeddings created
- âœ… 4 models trained and evaluated
- âœ… Best model saved with full performance report

---

## ğŸš€ What Makes This Special

<table>
<tr>
<td width="50%">

### ğŸ§  **Smart Arabic Processing**
Built specifically for Arabic's complexity:
- Handles diacritics, elongation, letter variants
- Context-aware stopword removal
- ISRI stemming for morphological richness
- Zero encoding issues

</td>
<td width="50%">

### âš¡ **Blazing Fast Workflow**
No more context switching:
- Single command = complete pipeline
- Automatic intermediate file handling
- Progress tracking at every step
- Resumable from any checkpoint

</td>
</tr>
<tr>
<td width="50%">

### ğŸ“Š **Production-Ready Outputs**
Everything you need to ship:
- Markdown reports with metrics
- classification reports
- Saved models ready for deployment
- Beautiful visualizations for stakeholders

</td>
<td width="50%">

### ğŸ¨ **Visual Insights**
Understand your data instantly:
- Class distribution analysis
- Text length patterns
- Top word frequencies
- Comparative model performance

</td>
</tr>
</table>

---


## ğŸŒŠ The Pipeline Flow
```
ğŸ“ Your CSV
    â†“
ğŸ” Data Validation
    â†“
ğŸ“Š Visual EDA
    â†“
ğŸ§¹ Arabic Preprocessing
    â†“
ğŸ§  Embedding Choice
    â”œâ”€â†’ âš¡ TF-IDF Vectors
    â””â”€â†’ ğŸ§  Model2Vec ARBERTv2
         â†“
    ğŸ“ Multi-Model Training
         â†“
    ğŸ“ˆ Performance Reports
         â†“
    â­ Best Model Selection
         â†“
    ğŸ‰ Production Ready!
```

---

## ğŸ› ï¸ Installation
### Setup in 3 Steps

```bash
# 1. Create virtual environment
python -m venv .venv

# 2. Activate it
# Windows:
.venv\Scripts\activate
# 3. Sync dependencies with uv
uv sync
# 4 Make sure you are in Arabic_NLP_Project_CLi
cd Arabic_NLP_Project_CLi
```



### Verify Installation

```bash
python main.py --help
```

**Expected output:**
```text
Usage: main.py [OPTIONS] COMMAND [ARGS]...

  Arabic NLP CLI Tool - End-to-end pipeline for Arabic text classification.

Options:
  --help  Show this message and exit.

Commands:
  pipeline  Run full pipeline: Load â†’ EDA â†’ Preprocess â†’ Embed â†’ Train
```

âœ… **You're ready to go!**

---

## ğŸ¬ Quick Start

### The One-Liner

```bash
python main.py pipeline CompanyReviews.csv review_description rating --embed model2vec
```

**What happens:**

<details>
<summary><b>ğŸ“¥ Step 1: Data Loading & Validation</b></summary>

```text
Step 1: Loading and validating data...
âœ“ Loaded: 40,046 rows, 4 columns
âœ“ Missing text rows: 1
âœ“ Number of classes: 3
âœ“ Step 1 finished successfully
```

The tool validates your CSV, checks for missing values, and confirms class distribution.

</details>

<details>
<summary><b>ğŸ“Š Step 2: Exploratory Data Analysis</b></summary>

```text
Step 2: Running EDA...
âœ“ Saved pie chart: outputs/visualizations/eda_class_distribution_pie.png
âœ“ Saved words histogram: outputs/visualizations/eda_text_length_words.png
âœ“ Saved chars histogram: outputs/visualizations/eda_text_length_chars.png
âœ“ Saved top words chart: outputs/visualizations/eda_top_words.png
âœ“ Step 2 finished successfully
```

Generates 4 publication-ready visualizations automatically.

</details>

<details>
<summary><b>ğŸ§¹ Step 3: Arabic Text Preprocessing</b></summary>

Your text transforms through:
- Diacritic removal: `Ù…ÙØ­ÙÙ…ÙÙ‘Ø¯` â†’ `Ù…Ø­Ù…Ø¯`
- Letter normalization: `Ø¥Ø³Ù„Ø§Ù…` â†’ `Ø§Ø³Ù„Ø§Ù…`
- Elongation handling: `ÙˆØ§Ø§Ø§Ø§Ùˆ` â†’ `ÙˆØ§Ùˆ`
- Stopword filtering
- ISRI stemming

**Result:** Clean, standardized Arabic ready for ML.

</details>

<details>
<summary><b>ğŸ§  Step 4: Semantic Embeddings</b></summary>

```text
Step 4: Creating embeddings...
ğŸ§  Model2Vec shape: (40,046, 128)
ğŸ’¾ Saved embeddings: outputs/embeddings/model2vec_embeddings.npy
âœ… Embeddings created successfully
```

Uses pre-trained ARBERTv2 for context-aware Arabic representations.

</details>

<details>
<summary><b>ğŸ“ Step 5: Model Training & Evaluation</b></summary>

```text
Step 5: Training and reporting...
ğŸ“ Saved report: outputs/reports/training_report_2026-01-17_14-32-08.md
â­ Best model: Random Forest (accuracy=0.7861)
ğŸ’¾ Saved best model: outputs/models/best_model_model2vec.pkl
âœ… Training completed successfully
```

Trains Logistic Regression, Random Forest, SVM, and Gradient Boosting simultaneously.

</details>

---

## ğŸ”¬ Under the Hood

### Preprocessing Pipeline

<table>
<thead>
<tr>
<th width="20%">Step</th>
<th width="40%">What It Does</th>
<th width="40%">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>ğŸ”¤ <b>Lowercasing</b></td>
<td>Standardize text case</td>
<td><code>Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ù…ÙŠÙ„</code> â†’ <code>Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ù…ÙŠÙ„</code></td>
</tr>
<tr>
<td>âœ¨ <b>Diacritic Removal</b></td>
<td>Strip Tashkeel marks (Ù‹ ÙŒ Ù Ù Ù Ù Ù‘ Ù’)</td>
<td><code>Ù‡ÙÙˆÙ Ø¬ÙÙ…ÙÙŠÙ„ÙŒ</code> â†’ <code>Ù‡Ùˆ Ø¬Ù…ÙŠÙ„</code></td>
</tr>
<tr>
<td>ğŸ”„ <b>Letter Normalization</b></td>
<td>Unify letter variants</td>
<td><code>Ø¥Ø³Ù„Ø§Ù…ØŒ Ø£Ù…Ù„ØŒ Ø¢ÙŠØ©</code> â†’ <code>Ø§Ø³Ù„Ø§Ù…ØŒ Ø§Ù…Ù„ØŒ Ø§ÙŠØ©</code><br><code>Ù‰ â†’ ÙŠ, Ø© â†’ Ù‡, Ø¤ â†’ Ùˆ</code></td>
</tr>
<tr>
<td>â– <b>Elongation Removal</b></td>
<td>Collapse repeated characters</td>
<td><code>Ø±Ø§Ø§Ø§Ø§Ø§Ø¦Ø¹ Ø¬Ø¯Ø§Ø§Ø§Ø§Ø§</code> â†’ <code>Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ø§</code></td>
</tr>
<tr>
<td>ğŸ§¹ <b>Text Cleaning</b></td>
<td>Remove noise (numbers, punctuation, extra spaces)</td>
<td><code>Ø§Ù„Ø³Ø¹Ø± 500 Ø±ÙŠØ§Ù„!!!</code> â†’ <code>Ø§Ù„Ø³Ø¹Ø± Ø±ÙŠØ§Ù„</code></td>
</tr>
<tr>
<td>ğŸš« <b>Stopword Filtering</b></td>
<td>Remove common words from <code>arabic_stopwords.txt</code></td>
<td><code>Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„</code> â†’ <code>Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„</code></td>
</tr>
<tr>
<td>ğŸŒ± <b>ISRI Stemming</b></td>
<td>Extract word roots</td>
<td><code>ÙŠÙƒØªØ¨ÙˆÙ† Ø§Ù„ÙƒØªØ§Ø¨</code> â†’ <code>ÙƒØªØ¨ ÙƒØªØ¨</code></td>
</tr>
</tbody>
</table>

### Embedding Options

| Method | Dimensions | Speed | Best For | Command Flag |
|--------|-----------|-------|----------|--------------|
| **TF-IDF** | 5,000 | âš¡ Fast | Large datasets, keyword-focused tasks | `--embed tfidf` |
| **Model2Vec** | 128 | ğŸ¢ Moderate | Semantic understanding, small-medium data | `--embed model2vec` |

---

## ğŸ“ˆ Sample Results

### Training Report Snapshot

```markdown
# ğŸ“Š Training Report (Model2Vec ARBERTv2)

## Dataset Information
- **Rows:** 40,046  
- **Classes:** 3  
- **Embedding:** Model2Vec (128 dimensions)

## ğŸ† Best Model: Random Forest

**Accuracy:** 78.61%

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Negative | 0.75 | 0.71 | 0.73 | 2,840 |
| Neutral | 0.24 | 0.01 | 0.02 | 385 |
| Positive | 0.80 | 0.89 | 0.85 | 4,785 |

**Confusion Matrix:**
```
[[2013    4  823]
 [ 160    4  221]
 [ 496    9 4280]]
```
```

---

## ğŸ“ Output Structure

After running the pipeline, you'll find:

```
outputs/
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ eda_class_distribution_pie.png
â”‚   â”œâ”€â”€ eda_text_length_words.png
â”‚   â”œâ”€â”€ eda_text_length_chars.png
â”‚   â””â”€â”€ eda_top_words.png
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ model2vec_embeddings.npy
â”‚   â””â”€â”€ model2vec_model.pkl
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model_model2vec.pkl
â””â”€â”€ reports/
    â””â”€â”€ training_report_2026-01-17_14-32-08.md
```
---
<div align="center">

**Made with â¤ï¸ for the Arabic NLP
 Week At SDAIA BootCamp**


</div>
